%
% Halaman Abstrak
%
% @author  Andreas Febrian
% @version 2.2.0
% @edit by Ichlasul Affan
%

\chapter*{Abstrak}
\singlespacing

\noindent \begin{tabular}{l l p{10cm}}
	\ifx\blank\npmDua
	Nama                           & :  & \penulisSatu                \\
	Program Studi                  & :  & \programSatu                \\
	\else
	Nama Penulis 1 / Program Studi & :  & \penulisSatu~/ \programSatu \\
	Nama Penulis 2 / Program Studi & :  & \penulisDua~/ \programDua   \\
	\fi
	\ifx\blank\npmTiga\else
	Nama Penulis 3 / Program Studi & :  & \penulisTiga~/ \programTiga \\
	\fi
	Judul                          & :  & \judul                      \\
	Pembimbing                     & :  & \pembimbingSatu             \\
	\ifx\blank\pembimbingDua
	\else
	\                              & \  & \pembimbingDua              \\
	\fi
	\ifx\blank\pembimbingTiga
	\else
	\                              & \  & \pembimbingTiga             \\
	\fi
\end{tabular} \\

\vspace*{0.5cm}

\noindent Lanskap kecerdasan buatan (AI) belakangan ini mengalami pergeseran fundamental.
Fokus industri yang sebelumnya terpaku pada perlombaan memperbesar skala model bahasa (\textit{Large Language Models} - LLM), kini beralih menuju efisiensi dan aksesibilitas melalui \textit{Small Language Models} (SLM). Dengan parameter di bawah 10 miliar, model-model ini menjanjikan demokratisasi teknologi: memungkinkan AI canggih berjalan di perangkat dengan sumber daya terbatas, sebuah keunggulan vital bagi negara berkembang seperti Indonesia. Namun, pengecilan ukuran ini memantik pertanyaan kritis: apakah kapasitas penalaran kognitifnya turut menyusut terutama pada tugas logika kompleks di mana model kecil rentan berhalusinasi atau mengambil jalan pintas penalaran (\textit{greedy reasoning})?

Penelitian ini menjawab tantangan tersebut dengan menguji efektivitas pendekatan \textit{Neuro-Symbolic}, sebuah metode hibrida yang menggunakan fleksibilitas \textit{neural models} dengan ketepatan matematika logika simbolik, untuk memperkuat kemampuan deduksi SLM pada dataset berbahasa Indonesia.
Penelitian ini menerapkan kerangka kerja \textit{Translation-Decomposition-Search-Resolution} pada tiga kategori model \textit{open-weight low-resource} (7B-9B, kuantisasi 4-bit): Qwen2.5-7B (Global), SEA-LION-v3-8B (Regional), dan SahabatAI-v1-8B (Nasional). Melalui serangkaian eksperimen menggunakan dataset logika ProntoQA yang diadaptasi ke Bahasa Indonesia, terungkap perbedaan performa yang antara metode konvensional dan pendekatan \textit{Neuro-Symbolic}.

Temuan empiris menunjukkan sebuah anomali: model global Qwen2.5 yang mendominasi pada penalaran implisit (81.00\%), justru mengalami kegagalan katastropik (anjlok ke 14.00\%) saat dipaksa mematuhi batasan sintaksis ketat dalam \textit{pipeline} simbolik. Sebaliknya, model regional SEA-LION v3 justru mencatat performa tertinggi (81.60\%) dalam kerangka kerja ini.
Hal ini membuktikan bahwa penyelarasan bahasa (\textit{regional alignment}) merupakan faktor penentu dalam mengatasi hambatan penerjemahan semantik (\textit{Translation Bottleneck}).
Studi ini menyimpulkan bahwa untuk aplikasi yang menuntut reliabilitas logika tinggi di infrastruktur terbatas, mengintegrasikan SLM regional dengan \textit{solver} simbolik menawarkan solusi yang jauh lebih tangguh ketimbang sekadar mengandalkan intuisi probabilistik model semata.
\\

\vspace*{0.2cm}

\noindent Kata kunci: \\ \textit{Open-weight} SLM, Penalaran logika, ProntoQA bahasa Indonesia, Resolusi, \textit{framework} \\

\setstretch{1.4}
\newpage
