%
% Halaman Abstrak
%
% @author  Andreas Febrian
% @version 2.2.0
% @edit by Ichlasul Affan
%

\chapter*{Abstrak}
\singlespacing

\noindent \begin{tabular}{l l p{10cm}}
	\ifx\blank\npmDua
	Nama                           & :  & \penulisSatu                \\
	Program Studi                  & :  & \programSatu                \\
	\else
	Nama Penulis 1 / Program Studi & :  & \penulisSatu~/ \programSatu \\
	Nama Penulis 2 / Program Studi & :  & \penulisDua~/ \programDua   \\
	\fi
	\ifx\blank\npmTiga\else
	Nama Penulis 3 / Program Studi & :  & \penulisTiga~/ \programTiga \\
	\fi
	Judul                          & :  & \judul                      \\
	Pembimbing                     & :  & \pembimbingSatu             \\
	\ifx\blank\pembimbingDua
	\else
	\                              & \  & \pembimbingDua              \\
	\fi
	\ifx\blank\pembimbingTiga
	\else
	\                              & \  & \pembimbingTiga             \\
	\fi
\end{tabular} \\

\vspace*{0.5cm}

\noindent Kecerdasan buatan (AI) sedang mengalami perubahan yang besar. Industri yang dulunya fokus pada membangun model bahasa yang semakin besar (\textit{Large Language Models} - LLM), kini bergeser ke arah yang lebih efisien dan terjangkau melalui \textit{Small Language Models} (SLM). Model-model dengan parameter di bawah 10 miliar ini membuka peluang besar, yaitu teknologi AI canggih dapat berjalan bahkan di perangkat dengan keterbatasan sumber daya, sesuatu yang sangat penting bagi negara berkembang seperti Indonesia. Namun, pengurangan ukuran ini membawa tantangan: apakah kemampuan penalaran logikanya juga berkurang, khususnya dalam menangani tugas-tugas logika yang kompleks di mana model kecil mudah menghasilkan hasil yang tidak akurat?

Penelitian ini menjawab tantangan tersebut dengan menguji bagaimana pendekatan \textit{Neuro-Symbolic}, sebuah metode \textit{hybrid} yang menggabungkan fleksibilitas model neural dengan ketepatan logika simbolik, dapat meningkatkan kemampuan penalaran SLM pada data berbahasa Indonesia. Penelitian menerapkan sebuah pipeline lengkap: menerjemahkan pertanyaan ke logika formal (\textit{Translation to First Order Lofic}), mengubahnya menjadi bentuk normal konjungtif (\textit{Decomposition to Conjunctive Normal Form}), mencari klausa pelengkap (\textit{Search for Complementing Clause}), dan terakhir menggunakan resolusi dengan bukti kontradiksi (\textit{Resolution with Proof By Contradiction}). Eksperimen melibatkan tiga model \textit{open-weight} berukuran kecil (7B-9B parameter, dikuantisasi 4-bit): Qwen2.5-7B (global), SEA-LION-v3-8B (regional), dan SahabatAI-v1-8B (nasional). Menggunakan dataset logika ProntoQA yang adaptasi ke Bahasa Indonesia, penelitian ini membandingkan seberapa baik masing-masing model menangani tugas penalaran dengan dan tanpa \textit{framework Neuro-Symbolic}.

Hasil penelitian mengungkapkan temuan yang menarik: model global Qwen2.5, yang sebelumnya unggul dalam penalaran implisit (\textit{Naive Prompting}) dengan akurasi 81.00\%, justru mengalami penurunan drastis menjadi 14.00\% ketika diminta mematuhi aturan sintaksis ketat dalam \textit{pipeline} simbolik \textit{parsability error}. Di sisi lain, model regional SEA-LION v3 menunjukkan performa terbaik dibandingkan dengan dua model lain dalam penelitian ini dengan akurasi 81.60\% dalam \textit{framework} ini. Ini menunjukkan bahwa keselarasan linguistik regional memainkan peran penting dalam mengatasi hambatan penerjemahan semantik. Berdasarkan temuan ini, penelitian merekomendasikan bahwa untuk penalaran logika pada LLM dengan sumber daya terbatas, dapat menggunakan SLM regional dan menggunakan \textit{framework} \textit{Neuro-Symbolic} sebagai solusi yang lebih andal dibandingkan hanya mengandalkan intuisi probabilistik model semata. \\

\vspace*{0.2cm}

\noindent Kata kunci: \\ \textit{Open-weight} SLM, Penalaran logika, ProntoQA bahasa Indonesia, Resolusi, \textit{framework Translation to First Order Logic} \\

\setstretch{1.4}
\newpage
