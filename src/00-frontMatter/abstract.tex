%
% Halaman Abstract
%
% @author  Andreas Febrian
% @version 2.2.0
% @edit by Ichlasul Affan
%

\chapter*{ABSTRACT}
\singlespacing

\noindent \begin{tabular}{l l p{11.0cm}}
	\ifx\blank\npmDua
	Name                     & :  & \penulisSatu                     \\
	Study Program            & :  & \studyProgramSatu                \\
	\else
	Writer 1 / Study Program & :  & \penulisSatu~/ \studyProgramSatu \\
	Writer 2 / Study Program & :  & \penulisDua~/ \studyProgramDua   \\
	\fi
	\ifx\blank\npmTiga\else
	Writer 3 / Study Program & :  & \penulisTiga~/ \studyProgramTiga \\
	\fi
	Title                    & :  & \judulInggris                    \\
	Counselor                & :  & \pembimbingSatu                  \\
	\ifx\blank\pembimbingDua
	\else
	\                        & \  & \pembimbingDua                   \\
	\fi
	\ifx\blank\pembimbingTiga
	\else
	\                        & \  & \pembimbingTiga                  \\
	\fi
\end{tabular} \\

\vspace*{0.5cm}

\noindent Artificial Intelligence (AI) is undergoing a significant transformation. The industry, which previously focused on building increasingly larger language models (\textit{Large Language Models} - LLMs), is now shifting toward greater efficiency and affordability through \textit{Small Language Models} (SLMs). Models with fewer than 10 billion parameters open up vast opportunities, enabling advanced AI technology to run even on resource-constrained devices, a crucial factor for developing nations like Indonesia. However, this reduction in size brings challenges: is logical reasoning capability compromised, particularly when handling complex logical tasks where small models are prone to producing inaccurate results? 

This study addresses these challenges by examining how a \textit{Neuro-Symbolic} approach, a hybrid method combining the flexibility of neural models with the precision of symbolic logicâ€”can enhance SLM reasoning capabilities on Indonesian language data. The research implements a complete pipeline: translating questions to logic (\textit{Translation to First Order Logic}), converting them to conjunctive normal form (\textit{Decomposition to Conjunctive Normal Form}), searching for complementing clauses (\textit{Search for Complementing Clause}), and finally utilizing resolution with proof by contradiction (\textit{Resolution with Proof By Contradiction}). Experiments involved three small \textit{open-weight} models (7B-9B parameters, 4-bit quantized): Qwen2.5-7B (global), SEA-LION-v3-8B (regional), and SahabatAI-v1-8B (national). Using the ProntoQA logic dataset adapted into Indonesian, this research compares how well each model handles reasoning tasks with and without the \textit{Neuro-Symbolic framework}. 

The results reveal intriguing findings: the global model, Qwen2.5, which previously excelled in implicit reasoning (\textit{Naive Prompting}) with an accuracy of 81.00\%, experienced a drastic drop to 14.00\% when required to adhere to strict syntactic rules within the symbolic pipeline (due to \textit{parsability error}). Conversely, the regional model, SEA-LION v3, demonstrated the best performance compared to the other two models, achieving 81.60\% accuracy within this framework. This indicates that regional linguistic alignment plays a critical role in overcoming semantic translation barriers. Based on these findings, the research recommends that for logical reasoning on resource-constrained LLMs, utilizing regional SLMs combined with a \textit{Neuro-Symbolic framework} offers a more reliable solution than relying solely on the model's probabilistic intuition. \\

\vspace*{0.2cm}

\noindent Key words: \\ Open-weight LLM, logical reasoning, ProntoQA, resolution \\

\setstretch{1.4}
\newpage