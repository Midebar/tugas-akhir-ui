%-----------------------------------------------------------------------------%
\chapter{\babTiga}
\label{bab:3}
%-----------------------------------------------------------------------------%

Bab ini menguraikan rancangan operasional yang digunakan untuk menjawab rumusan masalah penelitian. Metodologi ini disusun untuk menguji secara empiris apakah pendekatan dapat mengatasi kelemahan penalaran probabilistik pada \textit{open-weight} \textit{Small Language Models} (SLM) dalam konteks Bahasa Indonesia.

Pendekatan penelitian ini bersifat kuantitatif-eksperimental. Fokus utamanya adalah mengukur akurasi penalaran logis pada bahasa Indonesia yang diperoleh melalui manipulasi struktur \textit{prompting} \textit{Neuro-Symbolic} dan dampaknya ketika model dijalankan dengan sumber daya terbatas (melalui kuantisasi).

%-----------------------------------------------------------------------------%
\section{Konfigurasi Model}
\label{sec:modelConfig}
%-----------------------------------------------------------------------------%

Mengingat bahwa adanya batasan sumber daya komputasi, maka eksperimen dijalankan menggunakan kuantisasi pada setiap model yang dijalankan menggunakan \textit{tools open-source}, yaitu \textit{llama.cpp} \footnote{\url{https://github.com/ggml-org/llama.cpp}}.

\subsection{Pemilihan Model}
Model yang dipilih mewakili tiga tingkatan spesialisasi bahasa untuk menguji hipotesis bahwa pemahaman dalam bahasa lokal membantu proses dekomposisi logika:
\begin{enumerate}
    \item \textbf{Qwen2.5-7B-Instruct (Representasi Global):} Model ini dipilih karena performanya yang unggul dalam benchmark logika matematika global, menjadi titik ukur batas atas kemampuan model \textit{open-weight} saat ini.
    \item \textbf{SEA-LION-v3-Llama-8B-Instruct (Representasi Regional):} Model yang telah melalui \textit{continued pre-training} dengan data bahasa dari negara-negara di Asia Tenggara, diharapkan memiliki pemahaman semantik yang lebih baik terhadap struktur kalimat regional.
    \item \textbf{SahabatAI-v1-Llama-8B-Instruct (Representasi Nasional):} Model yang dikhususkan untuk Bahasa Indonesia, juga sudah melalui \textit{continued pre-training}, digunakan untuk melihat apakah spesialisasi bahasa yang mendalam dapat menyelesaikan penalaran lebih baik dalam tugas logika.
\end{enumerate}

\subsection{Parameterisasi Inferensi}

Setiap model dijalankan dengan pengaturan parameter yang sama / konsisten untuk memastikan hasil eksperimen mencerminkan pengaruh variabel bebas, bukan perbedaan konfigurasi teknis. Strategi deterministik diterapkan untuk menghilangkan unsur \textit{randomness} dalam proses inferensi. 

\lstinputlisting[language=Python, caption=Konfigurasi parameter deterministik untuk setiap model yang digunakan, label=code:parameter_kwargs]{assets/codes/parameter_kwargs.py}

Parameter utama yang dikontrol adalah:

\begin{itemize}
    \item \textbf{\textit{Temperature}:} Ditetapkan ke 0.0 sehingga model hanya memilih token dengan probabilitas tertinggi tanpa penambahan noise acak (\textit{greedy decoding}). Hal ini memastikan setiap prompt menghasilkan output yang identik.
    \item \textbf{\textit{Max Tokens}:} Dibatasi sesuai dengan panjang output yang wajar untuk setiap tahap dalam pipeline, mencegah generasi yang berlebihan. Adapun token yang dibutuhkan untuk setiap tahap inferensi dalam \textit{framework} antara lain: proses translasi ke FOL memerlukan output setidaknya 400 token, proses dekomposisi setidaknya memerlukan output 700 token, dan proses pencarian bukti setidaknya memerlukan 1000 token., sehingga \textbf{\textit{max tokens}} yang di set untuk semua proses adalah 2500 untuk mengatasi \textit{overhead} atau halusinasi jika model tidak secara \textit{strict} mengikuti format.
    \item \textbf{\textit{n\_ctx}:} Ukuran konteks diatur untuk menentukan berapa banyak token sebelumnya yang dapat dipertimbangkan model saat menghasilkan respons. Nilai yang lebih besar memungkinkan model memahami konteks yang lebih panjang, namun meningkatkan penggunaan memori. \textbf{\textit{n\_ctx}} di set ke 0, sehingga ukuran konteks akan sesuai dengan kemampuan model masing-masing.
    \item \textbf{\textit{n\_gpu\_layers}:} Menentukan jumlah layer model yang dijalankan di GPU untuk akselerasi. Nilai yang lebih tinggi mempercepat inferensi tetapi memerlukan VRAM yang lebih besar. Nilai -1 berarti semua komputasi dilakukan di GPU.
\end{itemize}


%-----------------------------------------------------------------------------%
\section{Kerangka Kerja Aristotle}
\label{sec:aristotleFramework}
%-----------------------------------------------------------------------------%
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{assets/pics/Framework.drawio.png}
    \captionof{figure}{Kerangka kerja Aristotle untuk inferensi logika menggunakan SLM dan metode \textit{neuro-symbolic} (\cite{Aristotle25})}
    \label{fig:aristotle_framework}
\end{figure}
Penelitian ini mengimplementasikan \textit{framework} \textbf{Aristotle} (\cite{Aristotle25}) yang membagi proses inferensi menjadi empat modul utama, sesuai dengan Gambar ~\ref{fig:aristotle_framework}.

\subsection{Translasi Logika (\textit{Logical Translation})}
Ini adalah satu-satunya tahap yang menggunakan "kecerdasan" probabilistik SLM. Tujuannya adalah memetakan kalimat Bahasa Indonesia yang implisit menjadi struktur logika formal.

\begin{itemize}
    \item \textbf{Tugas Model:} Menerjemahkan narasi bahasa alami menjadi representasi \textit{First-Order Logic} (FOL) yang terdiri dari Fakta Atomik dan Aturan Implikasi.
    \item \textbf{Mekanisme Eksekusi:} Model diberikan \textit{few-shot prompt} yang berisi contoh pasangan kalimat Indonesia dan format logika target.
    \item \textbf{Format Output:}
          \begin{itemize}
              \item \textbf{Fakta:} $P$($Subjek, Nilai Kebenaran$). Contoh: $Wumpus$($Max, True$)
              \item \textbf{Aturan:} $P$($Subjek, Nilai Kebenaran$) $>>> P$($Objek, Nilai Kebenaran$). Contoh: $Wumpus$($\$x, True$) $>>> Manis$($\$x, False$)
              \item \textbf{Konjektur:} $P$($Subjek, Nilai Kebenaran$). Contoh: $Manis$($Max, True$)
          \end{itemize}
\end{itemize}

\subsection{Dekomposisi (\textit{Decomposer})}
Pada tahap ini, output FOL diproses lebih lanjut untuk memenuhi standar mesin pembukti teorema. Model diinstruksikan untuk melakukan konversi ke Prenex Normal Form(PNF) dan kemudian ke Conjunctive Normal Form (CNF). Proses penting di sini adalah Skolemisasi, yaitu penghapusan kuantor eksistensial (∃) yang sering menjadi sumber ambiguitas bagi model bahasa. Dalam dataset ProntoQA, tidak perlu dilakukan skolemisasi karena premis-premis dari dataset tersebut tidak memiliki kuantor eksistensial.

\begin{itemize}
    \item \textbf{Tugas Model:} Mengonversi aturan FOL menjadi \textit{Conjunctive Normal Form} (CNF) melalui serangkaian transformasi logis.
    \item \textbf{Mekanisme Eksekusi:}
          \begin{itemize}
              \item \textbf{PNF:} Konversi FOL ke bentuk PNF, di mana semua kuantor diletakkan di awal formula, diikuti oleh matriks bebas kuantor.
              \item \textbf{Skolemisasi:} Penghapusan kuantor eksistensial (∃) dengan mengganti variabel eksistensial dengan fungsi Skolem. Dataset ProntoQA tidak memerlukan langkah ini.
              \item \textbf{CNF:} Transformasi akhir ke CNF, di mana formula diekspresikan dalam bentuk konjungsi (AND) dari disjungsi (OR) literal.
          \end{itemize}
\end{itemize}

\subsection{Penyelesai Pencarian (\textit{Search Router})}
Mesin inti inferensi terdiri dari dua sub-komponen:
\begin{enumerate}
    \item \textbf{\textit{Logical Search Router}:} Memilih klausa mana yang relevan untuk diproses. Hal ini mencegah proses komputasi yang memerlukan resource terlalu banyak dan yang lama dalam pencarian bukti. Di sini juga dideklarasikan \textit{search\_round} yaitu batas maksimum iterasi pencarian bukti.
    \item \textbf{\textit{Logical Resolver}:} Menerapkan aturan resolusi secara iteratif hingga ditemukan kontradiksi (untuk pembuktian salah) atau hingga ruang pencarian habis.
\end{enumerate}

\subsection{Resolusi (\textit{Logical Resolver})}
Ini adalah mesin inferensi deterministik yang menggantikan peran penalaran SLM.

\begin{itemize}
    \item \textbf{Prinsip:} Menggunakan aturan resolusi berbasis pembuktian kontradiksi (\textit{Proof By Contradiction}) untuk menilai kebenaran hipotesis $S$ berdasarkan premis $P$ (~\ref{subsec:proof_by_contradiction})
    \item \textbf{Mekanisme Dual-Path:} Sistem mencoba membuktikan kebenaran hipotesis $S$ melalui dua jalur paralel pembuktian kontradiksi:
          \begin{enumerate}
              \item \textbf{Jalur A:} Asumsikan $\neg S$ (Negasi S), jika ditemukan kontradiksi (Klausa Kosong), maka $S$ terbukti \textbf{Benar}.
              \item \textbf{Jalur B:} Asumsikan $S$, jika ditemukan kontradiksi, maka $\neg S$ terbukti \textbf{Benar}.
          \end{enumerate}
    \item Jika tidak ada kontradiksi yang ditemukan di kedua jalur (misalnya karena informasi tidak lengkap atau translasi putus), sistem mengembalikan \textbf{Unknown}.
\end{itemize}

Mekanisme injeksi instruksi ke dalam \textit{prompt template} untuk setiap tahap diimplementasikan menggunakan kode dalam bahasa pemrograman Python berikut:

\lstinputlisting[language=Python, caption=Mekanisme injeksi data poin ke dalam template prompt Aristotle, label=code:prompt_replacement]{assets/codes/prompt_replacement.py}

Potongan kode di atas menunjukkan fungsi \textit{construct\_prompt\_a} yang bertugas membangun \textit{prompt} dinamis untuk masalah logika, dalam hal ini fungsi tersebut digunakan untuk membangun \textit{prompt} untuk tahap \textit{translation}. Fungsi ini membaca \textit{template} dasar yang memuat instruksi sistem dan contoh \textit{few-shot}, lalu mengganti \textit{placeholder}, seperti{{PREMISES}} dan {{CONJECTURE}} dengan data dari dataset ProntoQA yang sedang diuji. Pendekatan injeksi string ini memastikan bahwa struktur instruksi tetap konsisten (statis) sementara konten masalah berubah-ubah, meminimalkan risiko model "lupa" terhadap format output yang diminta saat beralih ke soal baru. Untuk setiap tahap dalam \textit{framework} Aristotle, kode serupa diterapkan dengan penyesuaian pada \textit{template} dan \textit{placeholder} yang relevan, misalnya \textit{template} untuk tahap \textit{decomposition} akan berbeda dengan tahap \textit{translation}, tetapi kode fungsi pembangun \textit{prompt} tetap mengikuti pola yang sama.

%-----------------------------------------------------------------------------%
\section{Teknik Evaluasi dan Analisis Data}
\label{sec:dataAnalysis}
%-----------------------------------------------------------------------------%

Untuk menjamin objektivitas, evaluasi tidak dilakukan secara manual melainkan menggunakan sistem ekstraksi berbasis pola (\textit{Regular Expression} / Regex).

\subsection{Parsing Bertingkat (Multi-stage Parsing)}
Sistem evaluasi dirancang untuk "menangkap" struktur logika dari output teks model. Kegagalan model dalam mematuhi format yang diminta pada tahap apa pun akan langsung dianggap sebagai kesalahan (\textit{failure}), tanpa upaya perbaikan manual. Ini adalah standar ketat yang diterapkan untuk menguji keandalan model sebagai komponen sistem logika.

\begin{itemize}
    \item \textbf{Ekstraksi FOL:} Mengambil Fakta, Aturan, dan Konjektur sesuai bloknya
          \lstinputlisting[language=Python, caption=Regex untuk ekstraksi blok Translasi, label=code:fol_regex]{assets/codes/translation_regex_grabs.py}
          Kode di atas menggunakan ekspresi reguler (\textit{Regular Expressions}) untuk mem-\textit{parsing output} dari tahap \textit{Logical Translation}. Pola regex dirancang untuk menangkap tiga komponen utama: blok "Fakta", "Konjektur" (seperti Manis(Jeruk)) dan blok "Aturan" (seperti Jeruk(x) >>> Manis(x)). Jika model menghasilkan teks naratif atau penjelasan di luar format yang ditentukan, regex ini akan mengabaikannya dan hanya mengambil struktur logika yang valid. Jika tidak ada struktur yang cocok, fungsi akan mengembalikan nilai kosong yang menandakan kegagalan translasi (\textit{parsability error}).
    \item \textbf{Ekstraksi CNF:} mengambil hasil akhir dari dekomposisi dari Aturan FOL.
          \lstinputlisting[language=Python, caption=Regex untuk ekstraksi blok Dekomposisi, label=code:decomposition_regex]{assets/codes/decomposition_regex_grabs.py}
          Serupa dengan tahap sebelumnya, kode pada \lst~\ref{code:decomposition_regex} bertugas memvalidasi output dari tahap \textit{Decomposer}. Regex ini secara spesifik mencari pola "Aturan dalam CNF". Jika model tidak mengikuti format yang diharapkan, regex ini akan gagal menemukan kecocokan, menandakan kegagalan dekomposisi.
    \item \textbf{Ekstraksi Resolusi:} Mendeteksi klausa baru dan kesimpulan akhir dalam label kecukupan.
          \lstinputlisting[language=Python, caption=Regex untuk memvalidasi langkah Resolusi, label=code:resolve_regex]{assets/codes/search_resolve_regex_grabs.py}
          \lst~\ref{code:resolve_regex} di atas adalah komponen validasi akhir yang bekerja pada output modul \textit{Resolver}. Regex ini bertugas mengekstraksi dua informasi vital dari logika resolusi SLM: (1) Clause Baru, yaitu kesimpulan antara yang dihasilkan dari penggabungan dua premis, dan (2) Label Cukup, yang menandakan apakah kontradiksi telah ditemukan (\textit{True}) atau belum (\textit{False}). Jika format ini tidak ditemukan, sistem akan menganggap langkah resolusi tersebut gagal atau tidak konklusif.
          
          
\end{itemize}

\subsection{Matriks Keputusan Evaluasi (Truth Table)}
Kinerja akhir model tidak ditentukan secara probabilistik, melainkan melalui tabel kebenaran logika berdasarkan hasil dari \textit{Logical Resolver}.
Untuk setiap pertanyaan $S$, sistem menjalankan dua pembuktian paralel. Tabel \ref{tab:decision_matrix} menunjukkan logika penentuan jawaban akhir.

\begin{table}[H]
    \centering
    \caption{Matriks Keputusan untuk Penentuan Label Jawaban (Kesimpulan)}
    \label{tab:decision_matrix}
    \renewcommand{\arraystretch}{1.5}
    \begin{tabularx}{\textwidth}{|c|X|X|l|}
        \hline
        \textbf{Kondisi}    & \centering\textbf{Jalur A: Buktikan $S$} & \centering\textbf{Jalur B: Buktikan $\neg S$} & \multirow{2}{*}{\textbf{Kesimpulan}} \\
        \textbf{(Skenario)} & \centering(Cari Kontradiksi di $\neg S$) & \centering(Cari Kontradiksi di $S$)           &                                      \\
        \hline
        1                   & \textbf{Berhasil} (Ada Kontradiksi)      & Gagal                                         & \textbf{TRUE}                        \\
        \hline
        2                   & Gagal                                    & \textbf{Berhasil} (Ada Kontradiksi)           & \textbf{FALSE}                       \\
        \hline
        3                   & Gagal                                    & Gagal                                         & \textbf{UNKNOWN}                     \\
        \hline
        4                   & \textbf{Berhasil}                        & \textbf{Berhasil}                             & \textbf{SELF-CONTRADICTORY}          \\
        \hline
    \end{tabularx}
\end{table}

\textbf{Keterangan:}
\begin{itemize}
    \item \textbf{Berhasil (Ada Kontradiksi):} Resolver menemukan klausa kosong, yang berarti asumsi awal salah, sehingga kebalikannya pasti benar.
    \item \textbf{TRUE:} Premis mendukung hipotesis $S$.
    \item \textbf{FALSE:} Premis menyangkal hipotesis $S$.
    \item \textbf{UNKNOWN:} Informasi pada premis tidak cukup untuk membuktikan atau menyangkal $S$.
    \item \textbf{SELF-CONTRADICTORY:} Premis itu sendiri tidak konsisten (mengandung konflik internal).
\end{itemize}