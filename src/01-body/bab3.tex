%-----------------------------------------------------------------------------%
\chapter{\babTiga}
\label{bab:3}
%-----------------------------------------------------------------------------%

Bab ini menjelaskan desain eksperimen, persiapan dataset ProntoQA, konfigurasi model, serta teknik evaluasi yang diadaptasi untuk Bahasa Indonesia.

Pendekatan penelitian ini bersifat kuantitatif-eksperimental. Evaluasi dilakukan dengan membandingkan dua skenario \textit{prompting}: (1) \textbf{Naive Prompting}, prompt langsung tanpa \textit{scaffolding} atau petunjuk langkah demi langkah, tetapi diberikan beberapa contoh pengerjaan. (2) \textbf{Prompting Terstruktur dengan Kerangka Aristotle}, \textit{prompt} yang dilakukan dengan \textit{prompt template} beserta contoh keluaran pada setiap tahapannya.

Hasil setiap percobaan diukur menggunakan metrik akurasi yang didefinisikan pada Bagian~\ref{sec:researchDesign} dan untuk melihat perbedaan signifikan pada perbedaan performa antar skenario \textit{prompting}. Semua eksperimen dijalankan deterministik (parameter inferensi seperti \code{temperature=0.0} dan \textit{fixed seed}) agar perbedaan kinerja mencerminkan efek prompting, bukan variansi sampling.

%-----------------------------------------------------------------------------%
\section{Desain Penelitian}
\label{sec:researchDesign}
%-----------------------------------------------------------------------------%
Penelitian ini bertujuan untuk mengisolasi kemampuan \textit{reasoning} model dari pengetahuan umumnya.
Oleh karena itu, desain penelitian difokuskan pada parameter-parameter berikut:

\begin{enumerate}
	\item \textbf{Variabel Bebas (\textit{Independent Variables}):}
	      \begin{itemize}
		      \item \textbf{Presisi Model:} Tingkat kuantisasi bobot model, dibagi menjadi dua level: \textit{Unquantized} (FP16/BF16) dan \textit{4-bit K-Quant Medium} (Q4\_K\_M).
	      \end{itemize}
	\item \textbf{Variabel Terikat (\textit{Dependent Variable}):}
	      \begin{itemize}
		      \item \textbf{Akurasi Logika (\textit{Strict Accuracy}):} Persentase jawaban yang benar secara biner (True/False) yang diekstraksi dari luaran \textit{framework}.
	      \end{itemize}
	\item \textbf{Variabel Kontrol:}
	      \begin{itemize}
		      \item Parameter model yang sama untuk memastikan kesetaraan antar model.
		      \item \textit{Prompt} dan \textit{data point} yang diberikan ke LLM.
	      \end{itemize}
\end{enumerate}

%-----------------------------------------------------------------------------%
\section{Instrumen Data: ProntoQA}
\label{sec:dataset}
%-----------------------------------------------------------------------------%
Penelitian ini menggunakan dataset \textbf{ProntoQA} (\textit{Prompting with Ontologies for QA}).
Pemilihan dataset ini didasarkan pada karakteristiknya yang sintetik dan tidak terlalu kompleks untuk dilakukan inferensi.
Penggunaan entitas fiktif (seperti "Wumpus", "Jompus") mencegah model menggunakan "hafalan" pengetahuan dunia, sehingga memaksa model untuk benar-benar melakukan deduksi berdasarkan premis yang diberikan.

\subsection{Adaptasi Linguistik dan Penerjemahan}
Dataset asli ProntoQA yang berbahasa Inggris diterjemahkan ke dalam Bahasa Indonesia.
Adapun kriteria dalam translasi dataset ke dalam Bahasa Indonesia:
Translasi dilakukan secara otomatis menggunakan LLM \textit{open-source} dengan \textit{prompting} menggunakan \textit{template}
Contoh: "Every X is Y" $\rightarrow$ "Setiap X adalah Y".

%-----------------------------------------------------------------------------%
\section{Konfigurasi Model dan Kuantisasi}
\label{sec:modelConfig}
%-----------------------------------------------------------------------------%
Kuantisasi model dilakukan menggunakan \code{llama.cpp} \cite{llama.cpp}, jika model tersebut belum memiliki versi kuantisasi yang ada pada repositori developer model tersebut

\subsection{Model Eksperimen}
Tiga arsitektur model digunakan untuk mewakili kategori global dan regional:
\begin{itemize}
	\item \textbf{Qwen2.5-7B-Instruct:} Mewakili model \textit{state-of-the-art} global dengan kemampuan matematika dan logika yang kuat.
	\item \textbf{SEA-LION-v3-Llama-8B-Instruct:} Mewakili model regional yang dilatih khusus dengan data Asia Tenggara (termasuk Bahasa Indonesia), untuk melihat apakah spesialisasi bahasa memberikan keuntungan pada penalaran.
	\item \textbf{SahabatAI-v1-Llama-8B-Instruct:} Mewakili model nasional yang dilatih khusus dengan data Bahasa Indonesia sesuai dengan dataset yang sudah ditranslasikan
\end{itemize}

\subsection{Skema Kuantisasi (Unquantized vs Q4\_K\_M)}
Penelitian ini juga membandingkan dua kondisi presisi bobot hanya sebagai benchmark pada naive prompting untuk melihat seberapa tingkat error dan kecepatan inferensi jika menggunakan metode kuantisasi dibandingkan dengan \textit{full precision}
\begin{enumerate}
	\item \textbf{Unquantized (FP16/BF16):}
	      Model dijalankan pada presisi aslinya (16-bit). Ini berfungsi sebagai \textit{baseline} performa ideal (maksimal).
	\item \textbf{Q4\_K\_M (4-bit K-Quant Medium):}
	      Model dikompresi menggunakan metode \textit{k-quantization} tipe Medium.
	      Metode ini dipilih karena menyeimbangkan ukuran dan akurasi dengan cara:
	      \begin{itemize}
		      \item Bobot \textit{Attention.v} (output value) dan sebagian \textit{Feed-Forward} disimpan dengan presisi lebih tinggi (6-bit) karena krusial untuk akurasi.
		      \item Bobot lainnya dikuantisasi ke 4-bit.
	      \end{itemize}
\end{enumerate}

%-----------------------------------------------------------------------------%
\section{Prosedur Eksperimen}
\label{sec:procedure}
%-----------------------------------------------------------------------------%

\subsection{Teknik Prompting}
Setiap input ke model diformat menggunakan prompt template dan menambahkan sebuah data point dan diteruskan ke LLm untuk diproses
Struktur \textit{prompt} terdiri dari:
\begin{enumerate}
	\item \textbf{Instruksi Sistem:} Menetapkan persona (misal: "Anda adalah ahli logika..") dan juga perintah dari user(misal: "Deskripsi tugas: Anda diberikan..")
	\item \textbf{Contoh:} Contoh soal logika beserta langkah penyelesaiannya (\textit{reasoning steps}).
	\item \textbf{Soal Target:} Premis dan pertanyaan dari dataset PrOntoQA yang harus dijawab sesuai dengan fungsi dari tahapan yang sedang dijalankan
\end{enumerate}

\subsection{Parameter Inferensi}
Untuk memastikan reprodusibilitas, model dan parameter diatur di dalam \textit{class} berikut:
\lstinputlisting[language=Python, caption=Kode untuk mendefinisikan kelas dan fungsi generate pada LLM, label=code:parameter_kwargs]{assets/codes/parameter_kwargs.py}

%-----------------------------------------------------------------------------%
\section{Teknik Analisis Data: Regex Adaptif}
\label{sec:dataAnalysis}
%-----------------------------------------------------------------------------%
Tantangan utama dalam mengevaluasi respons dalam Bahasa Indonesia adalah variasi linguistik dalam menyatakan kebenaran dan kesalahan.
Model tidak selalu menjawab sesuai dengan \textit{template} atau dalam formula yang diinginkan
Oleh karena itu, modul evaluasi standar ProntoQA dimodifikasi pada bagian load prompt template, pengiriman jawaban (\textit{question sending}), dan penangkapan hasil pengiriman(\textit{result grabbing}).

\subsection{Algoritma \textit{Load Template}}
Sistem menggunakan logika \textit{Regular Expression} (Regex) untuk mem-\textit{parse template} dan me-\textit{replace} label sesuai dengan formatnya

\begin{enumerate}
	\item Load file prompt template sesuai dengan fungsi yang ingin dijalankan
	\item Replace marker, seperti [[PREMISIS]] sesuai dengan data point
\end{enumerate}

Implementasi \textit{load template} untuk \textit{translation to first order logic}:
\lstinputlisting[language=Python, caption=Kode untuk memparse prompt template dengan data point, label=code:prompt_replacement]{assets/codes/prompt_replacement.py}

Kode tersebut kurang lebih sama untuk setiap tahapan fungsi dari translasi, dekomposisi, dan \textit{search\_resolve}

\subsection{Algoritma Pengiriman Jawaban (\textit{Question Sending})}
Sistem menggunakan modul \textit{generate} dari model untuk menghasilkan jawaban dari pertanyaan yang diberikan ke LLM

\begin{enumerate}
	\item Prompt template + data point yang sudah dimasukkan ke dalam prompt dikirim ke LLM
\end{enumerate}

Implementasi logika pengiriman jawaban untuk \textit{search resolve}:
\lstinputlisting[language=Python, caption=Kode untuk memberikan pertanyaan ke LLM, label=code:fol_translation_send]{assets/codes/search_resolve_generation.py}

\subsection{Algoritma Penangkapan Jawaban (\textit{Result Grabbing})}
Sistem menggunakan logika \textit{Regular Expression} (Regex) bertingkat untuk memparsing jawaban model.
Logika ini dirancang untuk kasus-kasus dari hasil generasi oleh LLM
\begin{enumerate}
	\item \textbf{Pendeteksian Bentuk Akhir:} Fokus pencarian dibatasi pada bagian respons pertama pada LLM karena menggunakan LLM berbasis instruksi "*-Instruct", sehingga lebih mudah untuk diisntruksikan dan hasilnya tidak jauh dari ekspektasi
	\item \textbf{Pola Regex Hirarkis:}
	      \begin{itemize}
		      \item \textbf{Naive Prompting:}
		            Mendeteksi blok "Penjelasan" dan blok "Jawaban" pada hasil generasi LLM
		      \item \textbf{Aristotle:} Mendeteksi \textit{boundary} antara jawaban dan template dan mengambil blok sesuai dengan regex
		            \begin{itemize}
			            \item \textbf{Translation to FOL:} Mendeteksi blok "Fakta", "Konjektur", dan "Aturan" sebagai hasil translasi ke FOL
			                  Implementasi kode:
			                  \lstinputlisting[language=Python, caption=Kode untuk mem-parse hasil dari LLM untuk translasi ke FOL, label=code:fol_translation_get]{assets/codes/translation_regex_grabs.py}
			            \item \textbf{Decomposition:} Mendeteksi blok "Aturan dalam CNF" dan "Skolemisasi" jika ada
			                  Implementasi kode:
			                  \lstinputlisting[language=Python, caption=Kode untuk mem-parse hasil dari LLM untuk translasi ke FOL, label=code:decomposition_get]{assets/codes/decomposition_regex_grabs.py}
			            \item \textbf{Search Resolve:} Mendeteksi blok "Clause Baru" dan "Label Cukup"
			                  Implementasi kode:
			                  \lstinputlisting[language=Python, caption=Kode untuk mem-parse hasil dari LLM untuk translasi ke FOL, label=code:search_resolve_get]{assets/codes/search_resolve_regex_grabs.py}
		            \end{itemize}
	      \end{itemize}
\end{enumerate}

\subsection{Metrik Evaluasi}
Akurasi dihitung berdasarkan perbandingan antara hasil parsing regex dengan kunci jawaban (\textit{Ground Truth}) dari dataset.
Jika model menghasilkan jawaban yang tidak dapat diparsing (misalnya, meracau atau tidak memberikan kesimpulan), maka dianggap sebagai jawaban dengan status "tidak diketahui" / \textit{unknown}
Hal ini memperketat standar evaluasi, karena kemampuan mengikuti instruksi (\textit{instruction following}) dianggap sebagai prasyarat dari penalaran yang valid.