%---------------------------------------------------------------
\chapter{\kesimpulan}
\label{bab:kesimpulan}
%---------------------------------------------------------------
Bab ini merangkum temuan-temuan utama yang diperoleh dari rangkaian eksperimen validasi kerangka kerja \textit{Neuro-Symbolic Aristotle} pada dataset logika berbahasa Indonesia. Kesimpulan disusun untuk menjawab rumusan masalah yang telah ditetapkan pada Bab 1, diikuti dengan saran strategis untuk pengembangan penelitian selanjutnya.

\section{Kesimpulan} \label{sec:kesimpulan}

Berdasarkan hasil evaluasi pada model \textit{open-weight} dengan parameter rendah (7B-9B) yang dikuantisasi pada dataset berbahasa Indonesia, penelitian ini menghasilkan tiga kesimpulan utama yang menjawab pertanyaan penelitian / rumusan masalah pada ~\ref{sec:rumusan} sesuai dengan urutannya:

\begin{enumerate} 
	\item \textbf{Mekanisme Penalaran Logis pada Bahasa Indonesia:}
	      Penalaran logis pada konteks Bahasa Indonesia dalam penelitian ini dilakukan melalui pembuatan sumber daya datamelalui adaptasi dari sumber data original dan eksekusi arsitektur \textit{Neuro-Symbolic}.
	      Proses ini diawali dengan adaptasi dataset, di mana dataset sintetis ProntoQA diterjemahkan ke dalam Bahasa Indonesia dengan mempertahankan struktur ontologi logika formal (fakta aturan, dan konjektur) namun menyesuaikan representasi linguistiknya.
	      Selanjutnya, mekanisme penalaran logis dijalankan melalui empat tahapan sekuensial dalam \textit{framework Aristotle}:
	      \begin{enumerate}
		      \item \textbf{\textit{Logical Translation}}, di mana SLM melakukan \textit{translation} narasi alamiah Indonesia ke dalam sintaks \textit{First-Order Logic} (FOL)
		      \item \textbf{\textit{Decomposition}}, yang mengonversi aturan dalam format FOL menjadi \textit{Conjunctive Normal Form} (CNF)
		      \item \textbf{\textit{Search Router}}, yang memilah klausa berkomplemen untuk disiapkan pada tahap resolusi
		      \item \textbf{\textit{Logical Resolver}}, yang melakukan deduksi deterministik menggunakan prinsip resolusi untuk menghasilkan jawaban yang valid secara simbolik dan mengembalikan ke \textit{Search Router} untuk mencari klausa baru
	      \end{enumerate}
	\item \textbf{Perbandingan Performa Antar Model Open-Weight:} \\
	      Terdapat perbedaan hasil yang signifikan antara model \textit{multilingual foundation model} dan model \textit{language-adaptive pre-trained model}, serta \textit{localized pre-trained model} dalam tugas resolusi dalam \textit{framework Aristotle}:
	      \begin{itemize}
		      \item \textbf{SEA-LION v3 (\textit{language-adaptive pre-trained model})} mencatat performa terbaik dengan akurasi \textbf{81.60\%}. Model ini menunjukkan keseimbangan terbaik antara pemahaman instruksi dalam Bahasa Indonesia dan kepatuhan terhadap format logika formal.
		      \item \textbf{Sahabat-AI v1 (\textit{localized pre-trained model})} menunjukkan performa yang stabil (\textbf{61.20\%}), mengungguli model \textit{multilingual foundation model} dalam memahami nuansa semantik lokal, meskipun masih di bawah SEA-LION dalam konsistensi sintaks kompleks.
		      \item \textbf{Qwen2.5 (\textit{multilingual foundation model})}, meskipun dikenal unggul dalam \textit{code generation}, mengalami kegagalan katastropik (\textbf{14.00\%}) pada metode ini. Kegagalan ini disebabkan oleh ketidakmampuan model untuk menjawab sesuai penalaran logis ketika dipaksa mengikuti format ketat, menandakan bahwa kapabilitas \textit{instruction following} tidak selalu berbanding lurus dengan kemampuan penalaran logis dalam konteks bahasa tertentu.
	      \end{itemize}
	\item \textbf{Efektivitas Aristotle vs Naive Prompting:} \\
	      Penerapan \textit{framework Aristotle} terbukti \textbf{meningkatkan reliabilitas} jika model memiliki kapabilitas \textit{instruction following} yang kuat dalam bahasa target.
	      \begin{itemize}
		      \item Pada model \textbf{SEA-LION}, penggunaan \textit{framework Aristotle} meningkatkan akurasi dari 76.80\% (\textit{Naive(CoT)}) menjadi \textbf{81.60\%}. Ini membuktikan bahwa \textit{framework Aristotle} dapat memanfaatkan kemampuan model untuk menghasilkan logika yang lebih tepat ketika diarahkan dengan benar.
		      \item Sebaliknya, pada model \textbf{Qwen2.5}, performa justru turun drastis dari 81.00\% (\textit{Naive(CoT)}) menjadi 14.00\% yang padahal jika kita telusuri pada ~\ref{sec:fol_ablation} hasail tersebut tidak jauh berbeda, bahkan dengan prolog pada ~\ref{sec:prolog_ablation} hasil tersebut lebih meningkat dibanding \textit{Naive(CoT)}. Hal ini menunjukkan bahwa model yang tidak dapat mematuhi atau terlalu patuh pada format \textit{prompt template} tidak akan menghasilkan penalaran logis yang baik, berbeda dengan \textit{Naive Prompting} yang lebih toleran terhadap kesalahan parsial.
		      \item \textit{Framework Aristotle} memiliki sifat \textit{brittle}, kesalahan kecil pada satu tahap akan merusak keseluruhan hasil atau \textit{error propagation}. Hal ini bisa dilihat pada penurunan performa Sahabat-AI dari 62.40\% (\textit{Naive(CoT)}) menjadi 61.20\% ketika menggunakan \textit{framework Aristotle} karena kesalahan pada tahap awal (seperti \textit{translation}) menyebabkan kegagalan pada tahap selanjutnya.
	      \end{itemize}
	\item \textbf{\textit{Ablation Study}:}
	      Dari hasil analisis pada studi ablasi, dapat disimpulkan bahwa untuk dataset ProntoQA, dengan menggunakan modul \textit{Translation to FOL} dari \textit{framework Aristotle} dan dilanjutkan dengan bantuan Prolog menghasilkan akurasi yang paling baik, ketimbang \textit{Naive Prompting} saja.
	      \begin{itemize}
		      \item Pada studi ablasi eksperimen resolusi dengan modul / tahap \textit{Translation to FOL} dan \textit{Decomposition to CNF} saja, rata-rata akurasi model untuk kasus ini, yaitu 58.60\%, lebih baik dari rata-rata akurasi model jika dilakukan secara penuh dengan tahap akhir \textit{Search \& Resolve}, yaitu 52.27\%, karena model Qwen tidak terkena \textit{parsability error}.
		      \item Eksperimen dengan menggunakan modul / tahap \textit{Translation to FOL} dan dilanjutkan dengan \textit{Prolog Converter \& Resolver} menghasilkan rata-rata akurasi terbaik, yaitu 83.07\%, dibandingkan \textit{Translation to FOL} dan resolusi, yaitu 73.53\%, juga lebih baik jika dibandingkan dengan akurasi dari \textit{framework} secara keseluruhan untuk dataset ProntoQA, yaitu 52.27\%.
	      \end{itemize}
\end{enumerate}

\section{Saran}
\label{sec:saran}

Berdasarkan temuan dan keterbatasan penelitian ini, disarankan beberapa langkah pengembangan untuk penelitian selanjutnya:

\begin{enumerate} 
	\item \textbf{Penerapan Grammar-Constrained Decoding:}
	      Untuk mengatasi masalah \textit{parsability}, seperti yang dialami Qwen, penelitian lebih lanjut sebaiknya mengintegrasikan penegakan tata bahasa (seperti format GBNF\footnote{\url{https://github.com/ggml-org/llama.cpp/blob/master/grammars/README.md}}) saat inferensi. Ini akan memaksa model, bahkan yang terkuantisasi, untuk menghasilkan output yang 100\% valid secara sintaks, seperti mengikuti format FOL, sehingga evaluasi dapat berfokus murni pada logika semantik.
	\item \textbf{\textit{Fine-Tuning Khusus (Instruction Tuning)}:}
	      Alih-alih hanya mengandalkan \textit{Prompt Engineering} (\textit{few-shot}), disarankan untuk melakukan \textit{Fine-Tuning} ringan, seperti LoRA (\cite{hu2022lora}), pada model Sahabat-AI atau SEA-LION menggunakan dataset pasangan (Teks Indonesia ke bentuk FOL).
	      Hal ini akan meningkatkan konsistensi model dalam menangani struktur kalimat kompleks Bahasa Indonesia.
	\item \textbf{Peningkatan Kompleksitas Dataset:}
	      Penelitian ini hanya terbatas pada dataset ProntoQA (logika deduktif sintetik).
	      Pengujian selanjutnya perlu memperluas cakupan ke dataset, seperti menggunakan dataset yang dipakai pada penelitian Aristotle originalnya, yaitu ProofWriter (\cite{tafjord-etal-2021-proofwriter}) dan LogicNLI (\cite{tian-etal-2021-diagnosing}).
	\item \textbf{Penggunaan Metode Lain:}
	      Penelitian ini hanya membandingkan dua metode \textit{reasoning} dalam menangani penalaran logika, yaitu \textit{Naive Prompting} dan \textit{Framework Aristotle}. Untuk penelitian kedepannya bisa menggunakan atau penambahan metode \textit{reasoning}, seperti \textit{Aggregative Reasoning}, seperti \textit{Tree-of-Thought} \cite{10.5555/3666122.3666639} atau pun Symbolic Reasoning selain \textit{framework Aristotle} ini.
\end{enumerate}