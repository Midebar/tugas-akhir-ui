%-----------------------------------------------------------------------------%
\chapter{Landasan Teori}
\label{bab:2}
%-----------------------------------------------------------------------------%

Bab ini merupakan kerangka teoretis yang mendasari analisis kemampuan LLM dalam melakukan inferensi logika, khususnya dalam konteks Bahasa Indonesia. Pembahasan mencakup arsitektur kognitif model bahasa, batasan deterministik dari model probabilistik, pendekatan \textit{neuro-symbolic}, serta kendala linguistik dan komputasi yang memengaruhi performa model pada sumber daya rendah (\textit{low-resource setting}).

%-----------------------------------------------------------------------------%
\section{Inferensi Logika pada Model Bahasa Besar}
\label{sec:logicInference}
%-----------------------------------------------------------------------------%

\subsection{Pergeseran Paradigma: Dari Pengenalan Pola ke Penalaran}
Perkembangan LLM telah menggeser fokus penelitian \textit{Natural Language Processing} (NLP) dari sekadar pengenalan pola statistik menjadi proses kognitif yang kompleks, termasuk penalaran (\textit{reasoning}). Dalam konteks ini, inferensi logika didefinisikan sebagai kemampuan model untuk menarik kesimpulan yang valid dari serangkaian premis yang diberikan, mengikuti aturan logika formal seperti deduksi, induksi, atau abduksi \cite{saparov2023languagemodelsgreedyreasoners}.

Namun, berbeda dengan sistem logika simbolik tradisional yang bersifat deterministik, LLM beroperasi berdasarkan probabilitas statistik. Hal ini menimbulkan pertanyaan mendasar mengenai apakah LLM benar-benar "bernalar" atau hanya melakukan peniruan pola argumen yang meyakinkan secara statistik.

\subsection{Hipotesis \textit{Greedy Reasoner}}
Salah satu kritik utama terhadap kemampuan penalaran LLM diajukan oleh Saparov dan He (2023) melalui hipotesis "Greedy Reasoner". Riset mereka menunjukkan bahwa model berbasis arsitektur Transformer cenderung menggunakan strategi pencarian (\textit{greedy search}) saat menyelesaikan rantai logika \cite{saparov2023languagemodelsgreedyreasoners}.

\begin{itemize}
	\item \textbf{Sifat Probabilistik Lokal:} Pada setiap langkah inferensi, model memprediksi token selanjutnya $P(w_t | w_{1:t-1})$ yang memiliki probabilitas tertinggi berdasarkan konteks lokal, tanpa mempertimbangkan validitas logika global dari keseluruhan argumen.
	\item \textbf{Ketidakmampuan \textit{Backtracking}:} Jika model mengambil langkah logika yang salah di awal, model cenderung "berhalusinasi" untuk membenarkan kesimpulan tersebut daripada kembali dan memperbaiki premis sebelumnya.
\end{itemize}

Keterbatasan ini sangat penting dalam konteks Bahasa Indonesia, di mana data pelatihan yang lebih sedikit dapat menyebabkan distribusi probabilitas token logika (seperti "jika", "maka", "kecuali") menjadi kurang \textit{robust} dibandingkan Bahasa Inggris.

%-----------------------------------------------------------------------------%
\section{Arsitektur \textit{Neuro-Symbolic}}
\label{sec:neuroSymbolic}
%-----------------------------------------------------------------------------%

Untuk mengatasi kelemahan penalaran probabilistik murni, pendekatan terkini mulai mengadopsi arsitektur \textit{Neuro-Symbolic} yang menggabungkan fleksibilitas semantik LLM dengan ketepatan logika simbolik. Salah satu kerangka kerja yang relevan adalah \textbf{Aristotle} yang diperkenalkan oleh Xu et al. (2025).

\subsection{Kerangka Kerja \textit{Translation - Decomposition - Search Resolver - Logic Resolution}}
Berdasarkan \cite{Aristotle25}, kerangka kerja Aristotle memisahkan proses pemahaman bahasa dari proses pembuktian logika melalui tiga modul utama:

\begin{enumerate}
	\item \textbf{Translation:} Menggunakan LLM untuk menerjemahkan premis bahasa natural menjadi bentuk logika standar atau \textit{First Order Logic} (FOL). Dalam konteks penelitian ini, modul ini berfungsi mengubah / mentranslasikan premis-premis yang ada menjadi representasi formal terstruktur, termasuk predikat / argumen, operator logika, dan kuantor, serta mengubah subjek yang dalam bentuk \textit{plural} menjadi bentuk \textit{singular}-nya.
	\item \textbf{Decomposition:} Dari hasil translasi pada tahap sebelumnya, premis-premis tersebut di dekomposisi ke dalam \textit{Prenex Normal Form} (PNF) dan \textit{Conjunctive Normal Form}(CNF). Lalu jika ada kuantor eksistensial, maka hasil dari dekomposisi CNF akan di dekomposisi dengan Skolemisasi untuk menghilangkan kuantor eksistensial tersebut.
	\item \textbf{Search Resolver:} Melakukan pencarian jalur pembuktian secara sistematis. Berbeda dengan model generatif biasa yang hanya memprediksi kata berikutnya, modul ini mencari klausa pelengkap untuk membuktikan kontradiksi (\textit{Proof by Contradiction}).
	\item \textbf{Logical Resolution:} Menyelesaikan konflik logika secara deterministik untuk menghasilkan keluaran biner (Benar/Salah), status "Tidak Diketahui" / \textit{Unknown}, dan status \textit{Self-Contradictory}, yang memberikan kepastian lebih tinggi dibandingkan teks generatif biasa.
\end{enumerate}


%-----------------------------------------------------------------------------%
\section{Tinjauan Model Terkini}
\label{sec:models}
%-----------------------------------------------------------------------------%

\subsection{Qwen2.5: Generalist Multilingual}
Qwen2.5 merupakan model mutakhir yang dilatih pada korpus masif (hingga 18 triliun token). Keunggulan utamanya terletak pada kemampuan generalisasi logika matematika dan pemrograman yang kuat \cite{qwen2.5, qwen2}. Meskipun bukan model khusus Bahasa Indonesia, skala pelatihannya yang masif memungkinkan munculnya kemampuan penalaran (\textit{emergent reasoning capabilities}) yang sering kali melampaui model yang lebih kecil namun spesifik.

\subsection{SEA-LION: Spesialis Regional}
SEA-LION (\textit{Southeast Asian Languages in One Network}) adalah inisiatif untuk membangun model yang selaras secara budaya dan linguistik untuk Asia Tenggara. Model ini dilatih ulang (\textit{continued pre-training}) dengan data bahasa yang digunakan pada Asia Tenggara, termasuk bahasa Indonesia, yang signifikan \cite{sea_lion_2024}. Secara teoretis, SEA-LION diharapkan memiliki pemahaman nuansa linguistik yang lebih baik, yang penting untuk tahap \textit{Logical Decomposer} dalam mendeteksi premis implisit dalam teks Bahasa Indonesia.

%-----------------------------------------------------------------------------%
\section{Evaluasi dan Benchmark}
\label{sec:benchmark}
%-----------------------------------------------------------------------------%

\subsection{IndoMMLU dan Keterbatasannya}
Benchmark standar untuk evaluasi LLM dalam Bahasa Indonesia saat ini adalah \textbf{IndoMMLU} \cite{koto-etal-2023-indommlu}. Dataset ini terdiri dari soal-soal ujian dari tingkat SD hingga Universitas.

Meskipun komprehensif, IndoMMLU memiliki keterbatasan fundamental untuk penelitian inferensi logika murni:
\begin{itemize}
	\item \textbf{Absennya Matematika Simbolik:} Koto et al. (2023) secara eksplisit mengecualikan soal matematika simbolik karena sudah terdapat dataset untuk soal tersebut, seperti GSM-8K \cite{cobbe2021trainingverifierssolvemath} dan NumGLUE \cite{mishra2022numgluesuitefundamentalchallenging}
	\item \textbf{\textit{Focus on Knowledge Crystallization}:} Sebagian besar tugas menguji ingatan akan fakta (\textit{crystallized knowledge}) seperti Sejarah atau Geografi, bukan kemampuan memanipulasi aturan logika (\textit{fluid reasoning}).
\end{itemize}

Oleh karena itu, penelitian ini perlu mengadaptasi benchmark logika formal (seperti ProntoQA) ke dalam Bahasa Indonesia untuk pengukuran yang lebih akurat.

%-----------------------------------------------------------------------------%
\section{Dampak Kuantisasi pada Inferensi}
\label{sec:quantization}
%-----------------------------------------------------------------------------%

Dalam skenario penggunaan praktis dengan sumber daya komputasi terbatas, sering kali penelitian menggunakan model yang sudah dikuantisasi (misalnya menggunakan format GGUF via \texttt{llama.cpp}) untuk mengurangi kebutuhan memori \cite{llama.cpp} ataupun mengurangi kebutuhan \textit{processing power}, khususnya untuk dataset yang besar.

Secara teoretis, kuantisasi (misalnya dari 16-bit ke 4-bit) berdampak non-linear terhadap kemampuan model:
\begin{enumerate}
	\item \textbf{Ketahanan Bahasa:} Kemampuan menghasilkan teks yang lancar (\textit{fluency}) relatif baik terhadap kuantisasi.
	\item \textbf{\textit{Logical Fragility}:} Inferensi logika sangat sensitif terhadap presisi numerik. Kesalahan pembulatan kecil pada bobot \textit{attention} dapat mengubah probabilitas operator negasi ("tidak") atau implikasi, yang berakibat fatal pada validitas rantai logika.
\end{enumerate}

%-----------------------------------------------------------------------------%
\section{Rangkuman}
\label{sec:summary}
%-----------------------------------------------------------------------------%

Berdasarkan tinjauan pustaka di atas, dapat disimpulkan bahwa kemampuan inferensi logika LLM pada Bahasa Indonesia bukan hanya fungsi dari ukuran model, tetapi merupakan interaksi kompleks antara arsitektur penalaran (Neuro-Symbolic vs Greedy). Kerangka pemikiran ini menjadi landasan bagi eksperimen yang akan dilakukan dalam penelitian ini.