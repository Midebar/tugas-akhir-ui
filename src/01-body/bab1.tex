%-----------------------------------------------------------------------------%
\chapter{\babSatu}
\label{bab:1}
%-----------------------------------------------------------------------------%

Bab ini memaparkan latar belakang, permasalahan, tujuan, batasan, manfaat, ringkasan metodologi, serta sistematika penulisan laporan ini. Penelitian ini berfokus pada evaluasi kemampuan penalaran logis oleh \textit{Small Language Models} (SLM) yang bersifat \textit{open-weight} ketika bekerja pada dataset berbahasa Indonesia dengan \textit{framework translation-decomposition-search-resolve}.

\section{Latar Belakang}
\label{sec:latBel}

Perkembangan \textit{Large Language Model} (LLM) telah mendorong kemajuan signifikan pada berbagai tugas pemrosesan bahasa natural seperti penerjemahan, ringkasan, dan tanya-jawab. Namun, kemampuan LLM untuk melakukan penalaran logis, yaitu melakukan inferensi yang benar dari himpunan premis dan aturan formal, masih menghadapi kendala fundamental. Evaluasi yang ketat menunjukkan bahwa model sering kali berfungsi sebagai mesin probabilistik yang menebak pola statistik alih-alih melakukan deduksi deterministik. Fenomena ini dijelaskan oleh \cite{saparov2023language} dalam penelitian mereka yang menunjukkan bahwa LLM sering gagal dalam inferensi multi-langkah karena mereka mengambil jalan pintas heuristik daripada mengikuti rantai logika yang valid.

Selama dekade terakhir, perkembangan \textit{Natural Language Processing} (NLP) didorong oleh (\textit{scaling laws}) yang menyatakan bahwa peningkatan jumlah parameter, data, dan komputasi akan secara linear meningkatkan performa model. Era ini melahirkan model-model raksasa atau \textit{Large Language Models} (LLM) dengan ratusan juta parameter, seperti GPT-4 dan Llama-3-405B. Model-model ini menunjukkan kemampuan \textit{emergent} yang luar biasa, namun keberhasilan ini datang dengan biaya infrastruktur komputasi yang masif dan konsumsi energi yang besar \cite{10.1145/3768165}.

Dalam konteks negara berkembang seperti Indonesia, ketergantungan pada LLM raksasa menjadi hambatan signifikan. Kebutuhan akan kedaulatan data dan privasi mendorong permintaan untuk menjalankan model secara lokal (\textit{on-premise}) atau di perangkat tepi (\textit{edge devices}). Untuk menghadapi tantangan ini, riset pada umumnya mulai beralih fokus pada \textit{Small Language Models} (SLM), yang umumnya memiliki parameter di bawah 10-14 miliar \cite{subramanian2025smalllanguagemodelsslms}. 

Namun, tantangan mendasar tetap membayangi utilitas SLM: kemampuan penalaran logis (\textit{logical reasoning}). Model bahasa pada dasarnya adalah mesin prediksi token probabilistik. Kelemahan ini dikenal sebagai masalah "halusinasi", sering kali lebih parah pada model kecil karena keterbatasan memori asosiatif \cite{saparov2023language}. Oleh karena itu, diperlukan pendekatan metodologis untuk memperkuat kapabilitas penalaran SLM tanpa memperbesar ukuran modelnya.

Untuk mengatasi kesenjangan antara kemampuan linguistik dan logika ini, berbagai metode prompting dan arsitektur telah dikembangkan. Berikut adalah sedikit tinjauan terhadap evolusi metode penalaran logis pada SLM yang menjadi landasan penelitian ini:
\begin{enumerate}
      \item \textit{Naive Prompting (Implicit Reasoning)}: Pendekatan paling dasar di mana model diminta langsung menjawab kesimpulan dari premis yang diberikan (misalnya, Zero-shot). Kelemahannya adalah "Curse of Complexity", di mana akurasi model menurun secara eksponensial seiring bertambahnya langkah logika karena model tidak memiliki memori kerja eksternal untuk menyimpan status inferensi perantara (\cite{saparov2023language}).
      \item \textit{Chain-of-Thought} (CoT): Diperkenalkan oleh \cite{Wei2022ChainOT}, CoT mendorong model untuk menghasilkan serangkaian langkah penalaran perantara sebelum memberikan jawaban akhir. Metode ini terbukti meningkatkan performa pada tugas aritmatika dan simbolik secara signifikan dengan mengubah pemetaan \textit{Input-Output} menjadi \textit{Input-Reason1-Reason2-Output}. Namun, CoT rentan terhadap propagasi kesalahan, jika satu langkah penalaran salah (halusinasi), seluruh kesimpulan akan salah karena tidak ada mekanisme verifikasi eksternal.
      \item Tree-of-Thoughts (ToT): \cite{10.5555/3666122.3666639} mengembangkan konsep CoT menjadi struktur pohon, memungkinkan model untuk mengeksplorasi berbagai jalur penalaran, melakukan \textit{lookahead}, dan \textit{backtracking} saat menemui jalan buntu. Meskipun lebih baik, ToT sangat mahal secara komputasi dan masih bergantung pada intuisi probabilistik model itu sendiri untuk mengevaluasi validitas setiap cabang pemikiran.
      \item \textit{Neuro-Symbolic Approaches} (Logic-LM \& SymbCoT): Untuk mencapai ketepatan logika yang \textit{strict}, pendekatan \textit{Neuro-Symbolic} mulai diadopsi. Logic-LM oleh \cite{pan-etal-2023-logic} menggunakan LLM hanya sebagai penerjemah masalah ke dalam kode simbolik (seperti Prolog) , yang kemudian diselesaikan oleh \textit{solver} deterministik. \cite{xu-etal-2024-faithful} kemudian mengusulkan SymbCoT yang mencoba mengintegrasikan verifikasi simbolik langsung ke dalam rantai pemikiran LLM.
      \item Aristotle \textit{Framework}: Penelitian ini berfokus pada \textit{Framework} Aristotle oleh \cite{Aristotle25}, yang menyempurnakan pendekatan \textit{Neuro-Symbolic} dengan arsitektur \textit{Translation-Decompose-Search-Resolve}. Keunggulan utamanya adalah adanya modul Search Router yang memangkas ruang pencarian premis yang tidak relevan, serta penggunaan dua jalur pembuktian untuk meminimalkan halusinasi.
\end{enumerate}

Meskipun metode-metode di atas menunjukkan hasil positif, sebagian besar penelitian dilakukan pada dataset berbahasa Inggris. Studi terhadap kemampuan penalaran SLM pada bahasa lain, termasuk Bahasa Indonesia, masih terbatas. Perbedaan struktur linguistik (seperti ambiguitas subjek dalam Bahasa Indonesia) dan kualitas tokenisasi dapat memengaruhi performa model setelah adaptasi lintas bahasa. Selain itu, penelitian sebelumnya menggunakan \textit{proprietary} LLM (seperti GPT-4), sehingga perbandingan performa \textit{apple-to-apple} pada model \textit{open-weight} dengan sumber daya terbatas atau SLM belum banyak dikaji.

Dari gap penelitian yang sudah disebutkan, belum ada kajian mendalam mengenai efektivitas \textit{Framework} Aristotle pada dataset berbahasa Indonesia menggunakan open-weight SLM. Penelitian ini menjadi penting untuk mengevaluasi apakah model seperti Sahabat-AI (\textit{localized pre-trained} dengan Bahasa Indonesia) atau SEA-LION (\textit{language-adaptive pre-trained} dengan bahasa di regional ASEAN) ataupun Qwen (\textit{multilingual foundation model}) dapat mengatasi tantangan penalaran logis.

\section{Rumusan Masalah}
\label{sec:rumusan}

Berdasarkan latar belakang di atas, rumusan masalah penelitian ini adalah:
\begin{enumerate}
      \item Bagaimana penalaran logis pada dataset berbahasa Indonesia dilakukan dengan menggunakan \textit{framework translation-decompose-search-resolve}?
      \item Bagaimana perbandingan performa \textit{framework translation-decompose-search-resolve} untuk penalaran logis berbahasa Indonesia antar open-weight LLM berparameter rendah atau SLM?
      \item Bagaimana perbandingan performa \textit{framework translation-decompose-search-resolve} dibandingkan naive prompting untuk penalaran logis berbahasa Indonesia pada open-weight LLM berparameter rendah atau SLM?
\end{enumerate}

\section{Tujuan Penelitian}
\label{sec:tujuan}

Berikut adalah tujuan dari penelitian sesuai dengan latar belakang dan rumusan masalah

\textbf{Tujuan:}
\begin{enumerate}
      \item Mengimplementasikan penalaran logis pada dataset berbahasa Indonesia dilakukan dengan menggunakan \textit{framework translation-decompose-search-resolve}
      \item Mengukur perbandingan performa \textit{framework translation-decompose-search-resolve} untuk penalaran logis berbahasa Indonesia antar open-weight LLM berparameter rendah atau SLM
      \item Mengukur perbandingan performa \textit{framework translation-decompose-search-resolve} naive prompting untuk penalaran logis berbahasa Indonesia pada open-weight LLM berparameter rendah atau SLM
\end{enumerate}

\section{Batasan Penelitian}
\label{sec:batasan}

Penelitian ini dibatasi sebagai berikut:
\begin{itemize}
      \item \textbf{Dataset:} Fokus pada dataset diterjemahkan ke Bahasa Indonesia, yaitu ProntoQA saja
      \item \textbf{Model:} Eksperimen menggunakan model open-weight yang dapat dijalankan lokal maupun server, khususnya dengan kuantisasi. Model tersebut antara lain: Qwen2.5-7B-IT-GGUF, SEALIONv3-Llama-8B-IT-GGUF, dan SahabatAIv1-Llama-8B-IT-GGUF
      \item \textbf{Evaluasi:} Metrik utama adalah akurasi jawaban akhir terhadap ground truth.
      \item \textbf{Implementasi:} Source code yang tersedia pada repository Aristotle yang merupakan implementasi \textit{framework translation-decompose-search-resolve} (\cite{Aristotle25})
            % \item \textbf{Sumber daya:} Eksperimen disesuaikan dengan kapasitas komputasi dan biaya, sampling dimulai pada 10\% hingga 100\%.
\end{itemize}

\section{Manfaat Penelitian}
\label{sec:manfaat}

Penelitian ini diharapkan memberikan kontribusi yang bermakna bagi berbagai pihak:

\begin{itemize}
      \item \textbf{Bagi pengembangan ilmu pengetahuan:} Penelitian ini dapat menambah pemahaman tentang kemampuan penalaran logis SLM pada bahasa Indonesia, sebuah aspek yang masih jarang dikaji. Temuan ini dapat menjadi fondasi bagi penelitian lanjutan dalam evaluasi model bahasa pada tugas-tugas penarlan logis kompleks dalam bahasa lokal.
            
      \item \textbf{Bagi praktisi dan pengembang:} Hasil analisis perbandingan model dan efektivitas \textit{framework} dapat menjadi panduan dalam memilih model open-weight yang tepat dan merancang pipeline pemrosesan bahasa untuk tugas penalaran logis berbahasa Indonesia, terutama dengan sumber daya komputasi terbatas.
            
      \item \textbf{Bagi komunitas penelitian terbuka:} Dataset ProntoQA yang diterjemahkan ke bahasa Indonesia, skrip eksperimen, serta laporan hasil penelitian akan dibagikan kepada publik. Kontribusi ini memungkinkan peneliti lain untuk mereplikasi, memvalidasi, dan melanjutkan penelitian dalam domain yang sama tanpa perlu melakukan terjemahan dan persiapan data dari awal.
\end{itemize}

%-----------------------------------------------------------------------------%
\section{Posisi Penelitian}
\label{sec:posisiPenelitian}
%-----------------------------------------------------------------------------%
Penelitian ini mengisi gap dalam literatur saat ini dengan menerapkan kerangka kerja \textit{Neuro-Symbolic} pada model berparameter rendah (\textit{low-resource}) yang dikuantisasi, khusus untuk Bahasa Indonesia.
\begin{table}[H]
      \centering
      \setlength{\tabcolsep}{5pt}
      \renewcommand{\arraystretch}{1.3}
      
      \begin{tabularx}{\textwidth}{
                  p{3cm}      % Peneliti
                  p{3.2cm}    % Metode
                  p{3cm}      % Model
                  X           % Keterbatasan
            }
            \toprule
            \textbf{Peneliti (Tahun)}                         & 
            \textbf{Metode / Framework}                       & 
            \textbf{Model / Bahasa / Dataset}                 & 
            \textbf{Keterbatasan (Gap)}                           \\
            \midrule
            
            Saparov \& He (2022)                              & 
            Naive Prompting \& CoT                            & 
            GPT-3 (175B) \newline
            Inggris \newline
            ProntoQA (Eng)                                    & 
            Hanya mengevaluasi model  \textit{proprietary high-resource}
            \\
            
            Pan et al.\ (2023)                                & 
            Logic-LM (Translate-Execute)                      & 
            GPT-3.5 / GPT-4 \newline
            Inggris \newline
            ProofWriter, ProntoQA                             & 
            Bergantung pada solver eksternal tanpa mekanisme \textit{search} untuk memangkas premis tidak relevan.
            \\
            
            Xu et al.\ (2025)                                 & 
            Aristotle (Translastion-Decompose-Search-Resolve) & 
            Llama-2 / GPT-4 \newline
            Inggris \newline
            LogicNLI, ProntoQA, ProofWriter                   & 
            \textit{Framework} yang efektif, tetapi belum diuji pada model LLM \textit{low-resource} dengan dataset berbahasa Indonesia.
            \\
            
            Koto et al.\ (2023)                               & 
            Evaluasi Benchmark                                & 
            IndoGPT, XGLM \newline
            Indonesia \newline
            IndoMMLU, IndoNLI                                 & 
            Fokus pada evaluasi pengetahuan umum, bukan penalaran logika formal yang membutuhkan multi-langkah penyelesaian.
            \\
            
            Penelitian Ini (2025)                             & 
            Aristotle (Translastion-Decompose-Search-Resolve) & 
            Qwen2.5, SEA-LION, Sahabat-AI \newline
            Indonesia \newline
            ProntoQA-ID                                       & 
            Menguji efektivitas \textit{translastion-decompose-search-resolve} pada model \textit{open-weight} kecil dan terkuantisasi.
            \\
            
            \bottomrule
      \end{tabularx}
      \caption{Perbandingan Penelitian Terkait Penalaran Logis dengan SLM}
      \label{tab:posisi_penelitian}
\end{table}

Dari tabel \tab~\ref{tab:posisi_penelitian}, terlihat bahwa penelitian-penelitian sebelumnya umumnya menggunakan model proprietary berukuran besar dan fokus pada bahasa Inggris. Penelitian ini menjembatani \textit{gap} tersebut dengan mengadaptasi \textit{framework translation-decompose-search-resolve} pada model \textit{open-weight} berparameter rendah pada dataset berbahasa Indonesia, sehingga memberikan wawasan baru tentang kemampuan penalaran logis dalam konteks sumber daya terbatas dan bahasa lokal.

%-----------------------------------------------------------------------------%
\section{Sistematika Penulisan}
\label{sec:sistematikaPenulisan}
%-----------------------------------------------------------------------------%
Sistematika penulisan laporan adalah sebagai berikut:
\begin{itemize}
      \item Bab 1 \babSatu \\
            Menguraikan motivasi penelitian, kesenjangan dalam literatur saat ini mengenai penalaran SLM bahasa Indonesia, rumusan masalah, dan tujuan spesifik validasi \textit{framework translation-decompose-search-resolve}.
      \item Bab 2 \babDua \\
            Menjelaskan prinsip-prinsip \textit{First-Order Logic} (FOL) dan aturan inferensi berdasarkan literatur klasik, serta tinjauan mendalam mengenai \textit{Neuro-Symbolic} dan evolusi dari \textit{Naive Prompting} ke \textit{framework translation-decompose-search-resolve}.
      \item Bab 3 \babTiga \\
            Mendeskripsikan desain eksperimen, proses adaptasi dataset ProntoQA ke Bahasa Indonesia, konfigurasi model, dan implementasi teknis \textit{framework translation-decompose-search-resolve}.
      \item Bab 4 \babEmpat \\
            Menyajikan data hasil akurasi antara Qwen, SEA-LION, dan Sahabat-AI. Bab ini akan menganalisis permasalahan pada tiap tahap \textit{framework} serta membandingkan hasilnya dengan metode Naive Prompting.
      \item Bab 5 \babLima \\
            Menyajikan data hasil eksperimen atau studi ablasi pada model-model yang digunakana serta proses melakukan proses resolusi atau evaluasi per tahap pada \textit{framework}
      \item Bab 6 \kesimpulan \\
            Merangkum temuan utama mengenai penggunaan model open-weight SLM untuk penalaran logis dan memberikan rekomendasi untuk penelitian selanjutnya di bidang penalaran logis pada bahasa Indonesia.
\end{itemize}
